{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from datasets import load_dataset\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection, naive_bayes\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Reusing dataset lex_glue (/Users/ytkd/.cache/huggingface/datasets/lex_glue/ecthr_a/1.0.0/c3c0bd7433b636dc39ae49a84dc401190c73156617efc415b04e9835a93a7043)\n",
      "100%|██████████| 3/3 [00:00<00:00, 229.36it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"lex_glue\",'ecthr_a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset['train']\n",
    "test = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(data):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    new_data = []\n",
    "    new_labels = []\n",
    "    for i in range(len(data)):\n",
    "        tokenized = [word_tokenize(entry.lower()) for entry in data[i]['text'] if entry not in stopwords.words('english')]\n",
    "        lemmatized = [[lemmatizer.lemmatize(token) for token in sent] for sent in tokenized]\n",
    "        new_data.append(lemmatized)\n",
    "        # new_data.append([word_tokenize(entry.lower()) for entry in data[i]['text'] if entry not in stopwords.words('english')])\n",
    "        new_labels.append(data[i]['labels'])\n",
    "    return new_data, new_labels\n",
    "\n",
    "def create_corpus(data):\n",
    "    corpus = []\n",
    "    for doc in data:\n",
    "        for sen in doc:\n",
    "            for word in sen:\n",
    "                corpus.append(word)\n",
    "    return corpus   \n",
    "\n",
    "def convert_2d(data):\n",
    "    lst2 = []\n",
    "    for i in data:\n",
    "        lst1 = []\n",
    "        for j in i:\n",
    "            for k in j:\n",
    "                lst1.append(k)\n",
    "        lst2.append(lst1)\n",
    "    return lst2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y  = pre_process(train) \n",
    "test_X, test_y = pre_process(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train  = create_corpus(train_X)\n",
    "corpus_test = create_corpus(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_2d = convert_2d(train_X)\n",
    "test_X_2d = convert_2d(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=identity_tokenizer, stop_words='english', lowercase=False)\n",
    "tfidf.fit(corpus_train+corpus_test)\n",
    "vectors_train = tfidf.fit_transform(train_X_2d)\n",
    "vectors_test = tfidf.transform(test_X_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_enc = MultiLabelBinarizer().fit_transform(train_y)\n",
    "test_y_enc = MultiLabelBinarizer().fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Model</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OneVsRestClassifier(estimator=SVC(C=1, kernel=...</td>\n",
       "      <td>52.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OneVsRestClassifier(estimator=SVC(C=1))</td>\n",
       "      <td>49.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OneVsRestClassifier(estimator=KNeighborsClassi...</td>\n",
       "      <td>38.60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OneVsRestClassifier(estimator=RandomForestClas...</td>\n",
       "      <td>34.40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OneVsRestClassifier(estimator=DecisionTreeClas...</td>\n",
       "      <td>32.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OneVsRestClassifier(estimator=MultinomialNB())</td>\n",
       "      <td>25.30%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Classification Model Accuracy Score\n",
       "1  OneVsRestClassifier(estimator=SVC(C=1, kernel=...         52.30%\n",
       "2            OneVsRestClassifier(estimator=SVC(C=1))         49.10%\n",
       "0  OneVsRestClassifier(estimator=KNeighborsClassi...         38.60%\n",
       "5  OneVsRestClassifier(estimator=RandomForestClas...         34.40%\n",
       "4  OneVsRestClassifier(estimator=DecisionTreeClas...         32.30%\n",
       "3     OneVsRestClassifier(estimator=MultinomialNB())         25.30%"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_models = [\n",
    "                         OneVsRestClassifier(KNeighborsClassifier(n_neighbors=3)),\n",
    "                         OneVsRestClassifier(SVC(kernel = \"linear\" ,C=1)),\n",
    "                         OneVsRestClassifier(SVC(kernel='rbf', C=1)),\n",
    "                         OneVsRestClassifier(naive_bayes.MultinomialNB()),\n",
    "                         OneVsRestClassifier(DecisionTreeClassifier()),\n",
    "                         OneVsRestClassifier(RandomForestClassifier(n_estimators=500)),\n",
    "                         ]\n",
    "\n",
    "model_scores = []\n",
    "for model in classification_models:\n",
    "  # Pipeline object is created to perform model training and evaluate the performance of each model.\n",
    "  model_pipeline = Pipeline([('model_training', model)])\n",
    "  model_pipeline.fit(vectors_train, train_y_enc)\n",
    "\n",
    "  model_name = model\n",
    "  if model_name=='SVC' and model.kernel=='rbf': \n",
    "    model_name+='RBF kernel'\n",
    "  \n",
    "  model_scores.append((model_name,(f'{100*model_pipeline.score(vectors_test, test_y_enc):.2f}%')))\n",
    "\n",
    "# Create the dataframe for score of each model\n",
    "df_model_scores = pd.DataFrame(model_scores,columns=['Classification Model','Accuracy Score'])\n",
    "df_model_scores.sort_values(by='Accuracy Score',axis=0,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
